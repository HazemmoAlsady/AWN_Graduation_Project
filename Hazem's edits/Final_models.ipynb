{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGEkdZ/V792Q9gIHh85SeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazemmoAlsady/AWN_Graduation_Project/blob/main/Hazem's%20edits/Final_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R_pY_i9X5o7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/cleaned_awn_data.xlsx')\n",
        "\n",
        "df = df[df[\"need_level\"] != \"Unknown\"].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "Qyuri4KVX9d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "1eVXLlLpX9vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "need_features = [\n",
        "    \"family_size\",\n",
        "    \"income_monthly\",\n",
        "    \"monthly_expenses\",\n",
        "    \"debts\",\n",
        "    \"number_of_children\",\n",
        "    \"age\",\n",
        "    \"expense_to_income_ratio\",\n",
        "    \"case_type\",\n",
        "    \"housing_type\",\n",
        "    \"health_status\",\n",
        "    \"city\",\n",
        "    \"gender\"\n",
        "]\n",
        "\n",
        "X = df[need_features]\n",
        "y = df[\"need_level\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "L0FmzXtXYCtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "cat_cols = X.select_dtypes(include=\"object\").columns\n",
        "num_cols = X.select_dtypes(exclude=\"object\").columns\n",
        "\n",
        "need_preprocessor = ColumnTransformer([\n",
        "    (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ]), cat_cols)\n",
        "])\n"
      ],
      "metadata": {
        "id": "CzFpyNxkYDH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "need_level_model = Pipeline(steps=[\n",
        "    (\"preprocess\", need_preprocessor),\n",
        "    (\"model\", RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=15,\n",
        "        min_samples_split=10,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n"
      ],
      "metadata": {
        "id": "QAOlGYIDYEjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "need_level_encoder = LabelEncoder()\n",
        "y_train_enc = need_level_encoder.fit_transform(y_train)\n"
      ],
      "metadata": {
        "id": "OfY9uQ3CYG1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "need_level_model.fit(X_train, y_train_enc)\n"
      ],
      "metadata": {
        "id": "xhhw8KFtYJ7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred = need_level_model.predict(X_test)\n",
        "y_pred = need_level_encoder.inverse_transform(y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    cmap=\"Blues\"\n",
        ")\n",
        "plt.title(\"Need Level – Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c-1nvbwBb2cv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Encode y_test\n",
        "y_test_enc = need_level_encoder.transform(y_test)\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        max_iter=2000,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=15,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=3,\n",
        "        n_estimators=300,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipe = Pipeline([\n",
        "        (\"preprocess\", need_preprocessor),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "\n",
        "    pipe.fit(X_train, y_train_enc)\n",
        "    preds = pipe.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test_enc, preds)\n",
        "    results.append((name, acc))\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\"])\n",
        "results_df\n"
      ],
      "metadata": {
        "id": "g0OUggV9b5rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = need_level_model.named_steps[\"model\"]\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"feature\": num_cols.tolist() +\n",
        "               list(need_level_model.named_steps[\n",
        "                   \"preprocess\"\n",
        "               ].transformers_[1][1]\n",
        "               .named_steps[\"onehot\"]\n",
        "               .get_feature_names_out(cat_cols)),\n",
        "    \"importance\": importances\n",
        "}).sort_values(\"importance\", ascending=False)\n"
      ],
      "metadata": {
        "id": "bqzycckzb7-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.copy()\n",
        "df2 = df2[\n",
        "    (df2[\"assistance_type\"] != \"Unknown\") &\n",
        "    (df2[\"request_text\"] != \"Unknown\")\n",
        "].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "Nb_CmnPbYLaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    leakage_words = [\n",
        "        \"سلة\", \"غذائية\", \"طعام\",\n",
        "        \"علاج\", \"أدوية\", \"عملية\",\n",
        "        \"مدارس\", \"تعليم\",\n",
        "        \"كرسي\", \"إعاقة\",\n",
        "        \"مالية\", \"إيجار\", \"سكن\"\n",
        "    ]\n",
        "    for w in leakage_words:\n",
        "        text = re.sub(w, \"\", text)\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "df2[\"request_text_clean\"] = df2[\"request_text\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "6pwlW6rCYNPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = [\n",
        "    \"family_size\", \"income_monthly\", \"monthly_expenses\",\n",
        "    \"debts\", \"number_of_children\", \"age\",\n",
        "    \"expense_to_income_ratio\"\n",
        "]\n",
        "\n",
        "cat_features = [\n",
        "    \"housing_type\",\n",
        "    \"health_status\",\n",
        "    \"city\",\n",
        "    \"gender\"\n",
        "]\n",
        "text_feature = \"request_text_clean\"\n",
        "\n",
        "X = df2[num_features + cat_features + [text_feature]]\n",
        "y = df2[\"assistance_type\"]\n"
      ],
      "metadata": {
        "id": "G_No1F6eYOug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "_qbnSvwqYQO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "assist_preprocessor = ColumnTransformer([\n",
        "    (\"text\", TfidfVectorizer(max_features=1500, ngram_range=(1,1), min_df=5), text_feature),\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ]), cat_features),\n",
        "    (\"num\", SimpleImputer(strategy=\"median\"), num_features)\n",
        "])\n"
      ],
      "metadata": {
        "id": "mt7HdwBdYRtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        " (\"model\", XGBClassifier(\n",
        "    objective=\"multi:softprob\",\n",
        "    num_class=len(assistance_encoder.classes_),\n",
        "    n_estimators=400,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        "))"
      ],
      "metadata": {
        "id": "xwnsQZ-sYUPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistance_encoder = LabelEncoder()\n",
        "y_train_enc = assistance_encoder.fit_transform(y_train)\n"
      ],
      "metadata": {
        "id": "KOZGXhEyYVnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistance_model.fit(X_train, y_train_enc)\n"
      ],
      "metadata": {
        "id": "mKTF_B7YYW-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=22,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=len(assistance_encoder.classes_),\n",
        "        n_estimators=300,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_enc = encoder.fit_transform(y)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"preprocess\", assist_preprocessor),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "\n",
        "    scores = cross_val_score(\n",
        "        pipe,\n",
        "        X,\n",
        "        y_enc,\n",
        "        cv=skf,\n",
        "        scoring=\"accuracy\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    results.append((name, np.mean(scores)))\n",
        "\n",
        "pd.DataFrame(results, columns=[\"Model\", \"CV Accuracy\"])"
      ],
      "metadata": {
        "id": "lpQQ3XLuq4mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/graduation_project/final_model\"\n",
        "os.makedirs(BASE_PATH, exist_ok=True)\n",
        "\n",
        "joblib.dump(need_level_model, f\"{BASE_PATH}/need_level_model.joblib\")\n",
        "joblib.dump(need_level_encoder, f\"{BASE_PATH}/need_level_encoder.joblib\")\n",
        "\n",
        "joblib.dump(assistance_model, f\"{BASE_PATH}/assistance_model.joblib\")\n",
        "joblib.dump(assistance_encoder, f\"{BASE_PATH}/assistance_encoder.joblib\")\n"
      ],
      "metadata": {
        "id": "XqIpaAeXYYJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/graduation_project/final_model\"\n",
        "os.makedirs(BASE_PATH, exist_ok=True)\n",
        "\n",
        "# Need Level Pipeline\n",
        "with open(f\"{BASE_PATH}/need_level_pipeline.pkl\", \"wb\") as f:\n",
        "    pickle.dump(need_level_model, f)\n",
        "\n",
        "# Need Level Encoder\n",
        "with open(f\"{BASE_PATH}/need_level_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(need_level_encoder, f)\n",
        "# Assistance Type Pipeline\n",
        "with open(f\"{BASE_PATH}/assistance_type_pipeline.pkl\", \"wb\") as f:\n",
        "    pickle.dump(assistance_model, f)\n",
        "\n",
        "# Assistance Type Encoder\n",
        "with open(f\"{BASE_PATH}/assistance_type_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(assistance_encoder, f)\n"
      ],
      "metadata": {
        "id": "-ErS8oZaYloT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "msfcq1F1sJtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1TOcgh377h1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ocpybg_W72oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = Pipeline([\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"clf\", XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=len(encoder.classes_),\n",
        "        n_estimators=400,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42\n",
        "    ))\n",
        "])"
      ],
      "metadata": {
        "id": "NObL5RZI76oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = cross_val_score(\n",
        "    model,\n",
        "    X_struct,\n",
        "    y_enc,\n",
        "    cv=skf,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Fold Scores:\", scores)\n",
        "print(\"Mean Accuracy:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "REyk4yFA78CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_struct, y_enc)\n"
      ],
      "metadata": {
        "id": "DLgkE7X-8PBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.DataFrame([{\n",
        "    \"income_monthly\": 2500,\n",
        "    \"debts\": 10000,\n",
        "    \"expense_to_income_ratio\": 4000/2500,\n",
        "    \"family_size\": 5,\n",
        "    \"number_of_children\": 3,\n",
        "    \"age\": 40,\n",
        "    \"health_status\": \"مريض ضغط\",\n",
        "    \"housing_type\": \"إيجار\"\n",
        "}])\n",
        "\n",
        "proba = model.predict_proba(sample)[0]\n",
        "\n",
        "for cls, p in zip(encoder.classes_, proba):\n",
        "    print(cls, round(p*100,2), \"%\")"
      ],
      "metadata": {
        "id": "SrrCeZM-79iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8HoQ2IO8CPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers accelerate sentence-transformers\n",
        "!pip install transformers accelerate --no-cache-dir -q"
      ],
      "metadata": {
        "id": "GWuQ6di_MWRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")"
      ],
      "metadata": {
        "id": "SDMnYe9LMWMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# فلترة البيانات\n",
        "df2 = df.copy()\n",
        "df2 = df2[\n",
        "    (df2[\"assistance_type\"] != \"Unknown\") &\n",
        "    (df2[\"request_text\"] != \"Unknown\")\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "df2[\"label\"] = encoder.fit_transform(df2[\"assistance_type\"])\n",
        "\n",
        "# Split\n",
        "train_df, test_df = train_test_split(\n",
        "    df2,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df2[\"label\"]\n",
        ")"
      ],
      "metadata": {
        "id": "r8LR9R3_MWKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv02\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "2ai50oy6MdzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = [\n",
        "    \"income_monthly\",\n",
        "    \"debts\",\n",
        "    \"expense_to_income_ratio\",\n",
        "    \"family_size\",\n",
        "    \"number_of_children\",\n",
        "    \"age\"\n",
        "]\n",
        "\n",
        "cat_features = [\n",
        "    \"health_status\",\n",
        "    \"housing_type\"\n",
        "]\n",
        "\n",
        "structured_all = pd.get_dummies(df2[num_features + cat_features])\n",
        "structured_cols = structured_all.columns"
      ],
      "metadata": {
        "id": "YhLphs7KMdwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AssistanceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.texts = df[\"request_text\"].astype(str).tolist()\n",
        "        self.labels = df[\"label\"].tolist()\n",
        "        self.structured = pd.get_dummies(\n",
        "            df[num_features + cat_features]\n",
        "        ).reindex(columns=structured_cols, fill_value=0).values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "        item[\"structured\"] = torch.tensor(self.structured[idx], dtype=torch.float)\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item"
      ],
      "metadata": {
        "id": "_PViM7p9Mdtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, bert, structured_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.structured_layer = nn.Linear(structured_size, 128)\n",
        "        self.classifier = nn.Linear(\n",
        "            bert.config.hidden_size + 128,\n",
        "            num_classes\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, structured, labels=None):\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs.pooler_output\n",
        "        structured_output = torch.relu(\n",
        "            self.structured_layer(structured)\n",
        "        )\n",
        "\n",
        "        combined = torch.cat((pooled_output, structured_output), dim=1)\n",
        "        logits = self.classifier(self.dropout(combined))\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(logits, labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ],
      "metadata": {
        "id": "i85zbTkfMdqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = AssistanceDataset(train_df)\n",
        "test_dataset = AssistanceDataset(test_df)\n",
        "\n",
        "model = HybridModel(\n",
        "    bert_model,\n",
        "    structured_size=len(structured_cols),\n",
        "    num_classes=len(encoder.classes_)\n",
        ")"
      ],
      "metadata": {
        "id": "lI9qr7-OMdl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    eval_strategy=\"epoch\",   # ✔ الصحيح في 4.41.2\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "8lDzRSBeMdjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Z9XkBDYBMdgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(test_dataset)\n",
        "y_pred = np.argmax(preds.predictions, axis=1)\n",
        "\n",
        "print(classification_report(\n",
        "    test_df[\"label\"],\n",
        "    y_pred,\n",
        "    target_names=encoder.classes_\n",
        "))"
      ],
      "metadata": {
        "id": "Eu5_QQSpMdeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XR5q6_WIMdbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OZtLO-8eMdZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z5hZ0PU4MdWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MbUWHXZVMdUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}